
    <!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==" crossorigin="anonymous" referrerpolicy="no-referrer" />

  <title>Zhihua Wang</title>
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">
</head>

<body>
    <div class="container">
        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="margin-bottom: 1em;">
            <h3 class="display-4" style="text-align: center;"><span style="font-weight: bold;">Zhihua</span> Wang</h3>
            </div>
            <br>
            <div class="col-md-8" style="">
                
                <p>I am a postDoc at City University of Hong Kong working on computational vision.</p>
                <p>
                    <span style="font-weight: bold;">Bio:</span> 
                    I received a B.E. degree from <a href="https://global.cumt.edu.cn/" target="_blank">the China University of Mining and Technology</a>, Xuzhou, China, in 2014, a M.S. degree from the <a href="https://english.nudt.edu.cn/" target="_blank"> National University of Defense Technology</a>, Changsha, China, in 2016, and a Ph.D.
                    degree from the <a href="https://www.cs.cityu.edu.hk/" target="_blank">Department of Computer Science, City University of Hong Kong</a>, Kowloon, Hong Kong, in 2022, under the supervision of <a href="https://kedema.org/" target="_blank">Dr. Kede Ma</a>. Now, I am working as a PostDoc with <a href="https://liaojing.github.io/html/" target="_blank">Dr. Jing Liao</a>.
                    My research interests include image quality assessment, computational vision, and human-computer interaction.
                </p>
                <p>For any inquiries, feel free to reach out to me via mail!</p>
                <p>
                    <a href="https://wangzhihua520.github.io/assets/pdf/CV_Zhihua.pdf" target="_blank" style="margin-right: 15px"><i class="fa fa-address-card fa-lg"></i> CV</a>
                    <a href="mailto:zhihua.wang@my.cityu.edu.hk" style="margin-right: 15px"><i class="far fa-envelope-open fa-lg"></i> Mail</a>
                    <a href="https://twitter.com/wongchiwa123" target="_blank" style="margin-right: 15px"><i class="fab fa-twitter fa-lg"></i> Twitter</a>
                    <a href="https://scholar.google.com/citations?user=0gKwEKMAAAAJ&hl=en" target="_blank" style="margin-right: 15px"><i class="fa-solid fa-book"></i> Scholar</a>
                    <a href="https://github.com/wangzhihua520" target="_blank" style="margin-right: 15px"><i class="fab fa-github fa-lg"></i> Github</a>
                    <a href="https://www.linkedin.com/in/zhihwang5/" target="_blank" style="margin-right: 15px"><i class="fab fa-linkedin fa-lg"></i> LinkedIn</a>
                </p>
    
            </div>
            <div class="col-md-4" style="">
                <img src="assets/img/profile.jpg" class="img-thumbnail" width="280px" alt="Profile picture">
            </div>
        </div>
        <div class="row" style="margin-top: 1em;">
            <div class="col-sm-12" style="">
                <h4>Publications</h4>
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/monosdf.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://niujinshuchong.github.io/monosdf/" target="_blank">MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface Reconstruction</a> <br>Zehao Yu, Songyou Peng, <span style="font-weight: bold";>Michael Niemeyer</span>, Torsten Sattler, Andreas Geiger <br><span style="font-style: italic;">Advances in Neural Information Processing Systems (NeurIPS)</span>, 2022 <br><a href="https://niujinshuchong.github.io/monosdf/" target="_blank">Project Page</a> / <a href="https://arxiv.org/pdf/2206.00665.pdf" target="_blank">Paper</a> / <a href="https://arxiv.org/pdf/2206.00665.pdf" target="_blank">Supplemental</a> / <a href="https://github.com/autonomousvision/monosdf" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseYu2022NEURIPS" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseYu2022NEURIPS"><div class="card card-body"><pre><code>@InProceedings{Yu2022NEURIPS, 
	author = {Zehao Yu and Songyou Peng and Michael Niemeyer and Torsten Sattler and Andreas Geiger}, 
	title = {MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface Reconstruction}, 
	booktitle = {Advances in Neural Information Processing Systems (NeurIPS)}, 
	year = {2022}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/voxgraf.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://katjaschwarz.github.io/voxgraf/" target="_blank">VoxGRAF: Fast 3D-Aware Image Synthesis with Sparse Voxel Grids</a> <br>Katja Schwarz, Axel Sauer, <span style="font-weight: bold";>Michael Niemeyer</span>, Yiyi Liao, Andreas Geiger <br><span style="font-style: italic;">Advances in Neural Information Processing Systems (NeurIPS)</span>, 2022 <br><a href="https://katjaschwarz.github.io/voxgraf/" target="_blank">Project Page</a> / <a href="https://arxiv.org/pdf/2206.07695.pdf" target="_blank">Paper</a> / <a href="https://arxiv.org/pdf/2206.07695.pdf" target="_blank">Supplemental</a> / <a href="https://github.com/autonomousvision/voxgraf" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseSchwarz2022NEURIPS" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseSchwarz2022NEURIPS"><div class="card card-body"><pre><code>@InProceedings{Schwarz2022NEURIPS, 
	author = {Katja Schwarz and Axel Sauer and Michael Niemeyer and Yiyi Liao and Andreas Geiger}, 
	title = {VoxGRAF: Fast 3D-Aware Image Synthesis with Sparse Voxel Grids}, 
	booktitle = {Advances in Neural Information Processing Systems (NeurIPS)}, 
	year = {2022}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/regnerf.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://m-niemeyer.github.io/regnerf" target="_blank">RegNeRF: Regularizing Neural Radiance Fields for View Synthesis from Sparse Inputs</a> <span style="color: red;">(Oral Presentation)</span><br><span style="font-weight: bold";>Michael Niemeyer</span>, Jonathan Barron, Ben Mildenhall, Mehdi Sajjadi, Andreas Geiger, Noha Radwan <br><span style="font-style: italic;">Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</span>, 2022 <br><a href="https://m-niemeyer.github.io/regnerf" target="_blank">Project Page</a> / <a href="https://drive.google.com/file/d/1S_NnmhypZjyMfwqcHg-YbWSSYNWdqqlo/view?usp=sharing" target="_blank">Paper</a> / <a href="https://drive.google.com/file/d/15ip8Fvfxp6rNRfBnbJEnFCjIJeFMH4CE/view?usp=sharing" target="_blank">Supplemental</a> / <a href="https://youtu.be/QyyyvA4-Kwc" target="_blank">Video</a> / <a href="https://drive.google.com/file/d/1kYknB2Ap3I3avstmPxAa9IiW8m85AZEF/view?usp=sharing" target="_blank">Poster</a> / <a href="https://github.com/google-research/google-research/tree/master/regnerf" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseNiemeyer2022CVPR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseNiemeyer2022CVPR"><div class="card card-body"><pre><code>@InProceedings{Niemeyer2022CVPR, 
	author = {Michael Niemeyer and Jonathan Barron and Ben Mildenhall and Mehdi Sajjadi and Andreas Geiger and Noha Radwan}, 
	title = {RegNeRF: Regularizing Neural Radiance Fields for View Synthesis from Sparse Inputs}, 
	booktitle = {Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)}, 
	year = {2022}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/sap.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://pengsongyou.github.io/sap" target="_blank">Shape As Points: A Differentiable Poisson Solver</a> <span style="color: red;">(Oral Presentation)</span><br>Songyou Peng, Chiyu Jiang, Yiyi Liao, <span style="font-weight: bold";>Michael Niemeyer</span>, Marc Pollefeys, Andreas Geiger <br><span style="font-style: italic;">Advances in Neural Information Processing Systems (NeurIPS)</span>, 2021 <br><a href="https://pengsongyou.github.io/sap" target="_blank">Project Page</a> / <a href="https://arxiv.org/abs/2106.03452" target="_blank">Paper</a> / <a href="https://youtu.be/FL8LMk_qWb4" target="_blank">Video</a> / <a href="https://pengsongyou.github.io/media/sap/sap_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/shape_as_points" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsePeng2021NEURIPS" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapsePeng2021NEURIPS"><div class="card card-body"><pre><code>@InProceedings{Peng2021NEURIPS, 
	author = {Songyou Peng and Chiyu Jiang and Yiyi Liao and Michael Niemeyer and Marc Pollefeys and Andreas Geiger}, 
	title = {Shape As Points: A Differentiable Poisson Solver}, 
	booktitle = {Advances in Neural Information Processing Systems (NeurIPS)}, 
	year = {2021}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/graf.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://ps.is.mpg.de/publications/schwarz2020neurips" target="_blank">GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis</a> <br>Katja Schwarz, Yiyi Liao, <span style="font-weight: bold";>Michael Niemeyer</span>, Andreas Geiger <br><span style="font-style: italic;">Advances in Neural Information Processing Systems (NeurIPS)</span>, 2020 <br><a href="https://ps.is.mpg.de/publications/schwarz2020neurips" target="_blank">Project Page</a> / <a href="http://www.cvlibs.net/publications/Schwarz2020NEURIPS.pdf" target="_blank">Paper</a> / <a href="http://www.cvlibs.net/publications/Schwarz2020NEURIPS_supplementary.pdf" target="_blank">Supplemental</a> / <a href="http://www.youtube.com/watch?v=akQf7WaCOHo&vq=hd1080&autoplay=1" target="_blank">Video</a> / <a href="https://github.com/autonomousvision/graf" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseSchwarz2020NEURIPS" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseSchwarz2020NEURIPS"><div class="card card-body"><pre><code>@InProceedings{Schwarz2020NEURIPS, 
	author = {Katja Schwarz and Yiyi Liao and Michael Niemeyer and Andreas Geiger}, 
	title = {GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis}, 
	booktitle = {Advances in Neural Information Processing Systems (NeurIPS)}, 
	year = {2020}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/giraffe.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://m-niemeyer.github.io/project-pages/giraffe/index.html" target="_blank">GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields</a> <span style="color: red;">(Oral Presentation, Best Paper Award)</span><br><span style="font-weight: bold";>Michael Niemeyer</span>, Andreas Geiger <br><span style="font-style: italic;">Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</span>, 2021 <br><a href="https://m-niemeyer.github.io/project-pages/giraffe/index.html" target="_blank">Project Page</a> / <a href="http://www.cvlibs.net/publications/Niemeyer2021CVPR.pdf" target="_blank">Paper</a> / <a href="http://www.cvlibs.net/publications/Niemeyer2021CVPR_supplementary.pdf" target="_blank">Supplemental</a> / <a href="http://www.youtube.com/watch?v=fIaDXC-qRSg&vq=hd1080&autoplay=1" target="_blank">Video</a> / <a href="http://www.cvlibs.net/publications/Niemeyer2021CVPR_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/giraffe" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseNiemeyer2021CVPR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseNiemeyer2021CVPR"><div class="card card-body"><pre><code>@InProceedings{Niemeyer2021CVPR, 
	author = {Michael Niemeyer and Andreas Geiger}, 
	title = {GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields}, 
	booktitle = {Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)}, 
	year = {2021}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/campari.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://github.com/autonomousvision/campari" target="_blank">CAMPARI: Camera-Aware Decomposed Generative Neural Radiance Fields</a> <br><span style="font-weight: bold";>Michael Niemeyer</span>, Andreas Geiger <br><span style="font-style: italic;">Proc. of the International Conf. on 3D Vision (3DV)</span>, 2021 <br><a href="https://github.com/autonomousvision/campari" target="_blank">Project Page</a> / <a href="https://arxiv.org/pdf/2103.17269.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Niemeyer2021THREEDV_supplementary.pdf" target="_blank">Supplemental</a> / <a href="http://www.youtube.com/watch?v=rrIIEc2qYjM" target="_blank">Video</a> / <a href="https://www.cvlibs.net/publications/Niemeyer2021THREEDV_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/campari" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseNiemeyer2021THREEDV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseNiemeyer2021THREEDV"><div class="card card-body"><pre><code>@InProceedings{Niemeyer2021THREEDV, 
	author = {Michael Niemeyer and Andreas Geiger}, 
	title = {CAMPARI: Camera-Aware Decomposed Generative Neural Radiance Fields}, 
	booktitle = {Proc. of the International Conf. on 3D Vision (3DV)}, 
	year = {2021}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/cslf.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2003.12406" target="_blank">Learning Implicit Surface Light Fields</a> <br>Michael Oechsle, <span style="font-weight: bold";>Michael Niemeyer</span>, Christian Reiser, Lars Mescheder, Thilo Strauss, Andreas Geiger <br><span style="font-style: italic;">Proc. of the International Conf. on 3D Vision (3DV)</span>, 2020 <br><a href="https://arxiv.org/abs/2003.12406" target="_blank">Project Page</a> / <a href="http://www.cvlibs.net/publications/Oechsle2020THREEDV.pdf" target="_blank">Paper</a> / <a href="http://www.cvlibs.net/publications/Oechsle2020THREEDV_supplementary.pdf" target="_blank">Supplemental</a> / <a href="http://www.cvlibs.net/publications/Oechsle2020THREEDV_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/cslf" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseOechsle2020THREEDV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseOechsle2020THREEDV"><div class="card card-body"><pre><code>@InProceedings{Oechsle2020THREEDV, 
	author = {Michael Oechsle and Michael Niemeyer and Christian Reiser and Lars Mescheder and Thilo Strauss and Andreas Geiger}, 
	title = {Learning Implicit Surface Light Fields}, 
	booktitle = {Proc. of the International Conf. on 3D Vision (3DV)}, 
	year = {2020}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/conv_onet.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://pengsongyou.github.io/conv_onet" target="_blank">Convolutional Occupancy Networks</a> <span style="color: red;">(Spotlight Presentation)</span><br>Songyou Peng, <span style="font-weight: bold";>Michael Niemeyer</span>, Lars Mescheder, Marc Pollefeys, Andreas Geiger <br><span style="font-style: italic;">Proc. of the European Conf. on Computer Vision (ECCV)</span>, 2020 <br><a href="https://pengsongyou.github.io/conv_onet" target="_blank">Project Page</a> / <a href="http://www.cvlibs.net/publications/Peng2020ECCV.pdf" target="_blank">Paper</a> / <a href="http://www.cvlibs.net/publications/Peng2020ECCV_supplementary.pdf" target="_blank">Supplemental</a> / <a href="http://www.youtube.com/watch?v=EmauovgrDSM&vq=hd1080&autoplay=1" target="_blank">Video</a> / <a href="https://github.com/autonomousvision/convolutional_occupancy_networks" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsePeng2020ECCV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapsePeng2020ECCV"><div class="card card-body"><pre><code>@InProceedings{Peng2020ECCV, 
	author = {Songyou Peng and Michael Niemeyer and Lars Mescheder and Marc Pollefeys and Andreas Geiger}, 
	title = {Convolutional Occupancy Networks}, 
	booktitle = {Proc. of the European Conf. on Computer Vision (ECCV)}, 
	year = {2020}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/dvr.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://avg.is.mpg.de/publications/niemeyer2020cvpr" target="_blank">Differentiable Volumetric Rendering: Learning Implicit 3D Representations without 3D Supervision</a> <br><span style="font-weight: bold";>Michael Niemeyer</span>, Lars Mescheder, Michael Oechsle, Andreas Geiger <br><span style="font-style: italic;">Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</span>, 2020 <br><a href="https://avg.is.mpg.de/publications/niemeyer2020cvpr" target="_blank">Project Page</a> / <a href="http://www.cvlibs.net/publications/Niemeyer2020CVPR.pdf" target="_blank">Paper</a> / <a href="http://www.cvlibs.net/publications/Niemeyer2020CVPR_supplementary.pdf" target="_blank">Supplemental</a> / <a href="https://www.youtube.com/watch?v=U_jIN3qWVEw" target="_blank">Video</a> / <a href="http://www.cvlibs.net/publications/Niemeyer2020CVPR_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/differentiable_volumetric_rendering" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseNiemeyer2020CVPR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseNiemeyer2020CVPR"><div class="card card-body"><pre><code>@InProceedings{Niemeyer2020CVPR, 
	author = {Michael Niemeyer and Lars Mescheder and Michael Oechsle and Andreas Geiger}, 
	title = {Differentiable Volumetric Rendering: Learning Implicit 3D Representations without 3D Supervision}, 
	booktitle = {Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)}, 
	year = {2020}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/oflow.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://avg.is.mpg.de/publications/niemeyer2019iccv" target="_blank">Occupancy Flow: 4D Reconstruction by Learning Particle Dynamics</a> <br><span style="font-weight: bold";>Michael Niemeyer</span>, Lars Mescheder, Michael Oechsle, Andreas Geiger <br><span style="font-style: italic;">Proc. of the IEEE International Conf. on Computer Vision (ICCV)</span>, 2019 <br><a href="https://avg.is.mpg.de/publications/niemeyer2019iccv" target="_blank">Project Page</a> / <a href="http://www.cvlibs.net/publications/Niemeyer2019ICCV.pdf" target="_blank">Paper</a> / <a href="http://www.cvlibs.net/publications/Niemeyer2019ICCV_supplementary.pdf" target="_blank">Supplemental</a> / <a href="http://www.youtube.com/watch?v=c0yOugTgrWc&vq=hd1080&autoplay=1" target="_blank">Video</a> / <a href="http://www.cvlibs.net/publications/Niemeyer2019ICCV_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/occupancy_flow" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseNiemeyer2019ICCV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseNiemeyer2019ICCV"><div class="card card-body"><pre><code>@InProceedings{Niemeyer2019ICCV, 
	author = {Michael Niemeyer and Lars Mescheder and Michael Oechsle and Andreas Geiger}, 
	title = {Occupancy Flow: 4D Reconstruction by Learning Particle Dynamics}, 
	booktitle = {Proc. of the IEEE International Conf. on Computer Vision (ICCV)}, 
	year = {2019}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/tfield.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://avg.is.mpg.de/publications/oechsle2019iccv" target="_blank">Texture Fields: Learning Texture Representations in Function Space</a> <span style="color: red;">(Oral Presentation)</span><br>Michael Oechsle, Lars Mescheder, <span style="font-weight: bold";>Michael Niemeyer</span>, Thilo Strauss, Andreas Geiger <br><span style="font-style: italic;">Proc. of the IEEE International Conf. on Computer Vision (ICCV)</span>, 2019 <br><a href="https://avg.is.mpg.de/publications/oechsle2019iccv" target="_blank">Project Page</a> / <a href="http://www.cvlibs.net/publications/Oechsle2019ICCV.pdf" target="_blank">Paper</a> / <a href="http://www.cvlibs.net/publications/Oechsle2019ICCV_supplementary.pdf" target="_blank">Supplemental</a> / <a href="http://www.youtube.com/watch?v=y8XHkl3vtpI&vq=hd1080&autoplay=1" target="_blank">Video</a> / <a href="http://www.cvlibs.net/publications/Oechsle2019ICCV_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/texture_fields" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseOechsle2019ICCV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseOechsle2019ICCV"><div class="card card-body"><pre><code>@InProceedings{Oechsle2019ICCV, 
	author = {Michael Oechsle and Lars Mescheder and Michael Niemeyer and Thilo Strauss and Andreas Geiger}, 
	title = {Texture Fields: Learning Texture Representations in Function Space}, 
	booktitle = {Proc. of the IEEE International Conf. on Computer Vision (ICCV)}, 
	year = {2019}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/onet.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://avg.is.mpg.de/publications/occupancy-networks" target="_blank">Occupancy Networks: Learning 3D Reconstruction in Function Space</a> <span style="color: red;">(Oral Presentation, Best Paper Finalist)</span><br>Lars Mescheder, Michael Oechsle, <span style="font-weight: bold";>Michael Niemeyer</span>, Sebastian Nowozin, Andreas Geiger <br><span style="font-style: italic;">Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</span>, 2019 <br><a href="https://avg.is.mpg.de/publications/occupancy-networks" target="_blank">Project Page</a> / <a href="http://www.cvlibs.net/publications/Mescheder2019CVPR.pdf" target="_blank">Paper</a> / <a href="http://www.cvlibs.net/publications/Mescheder2019CVPR_supplementary.pdf" target="_blank">Supplemental</a> / <a href="http://www.youtube.com/watch?v=w1Qo3bOiPaE&t=6s&vq=hd1080&autoplay=1" target="_blank">Video</a> / <a href="http://www.cvlibs.net/publications/Mescheder2019CVPR_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/LMescheder/Occupancy-Networks" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseMescheder2019CVPR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseMescheder2019CVPR"><div class="card card-body"><pre><code>@InProceedings{Mescheder2019CVPR, 
	author = {Lars Mescheder and Michael Oechsle and Michael Niemeyer and Sebastian Nowozin and Andreas Geiger}, 
	title = {Occupancy Networks: Learning 3D Reconstruction in Function Space}, 
	booktitle = {Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)}, 
	year = {2019}, 
}</pre></code></div></div> </div> </div> </div>
            </div>
        </div>
        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="">
                <h4>Talks</h4>
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/diffrend.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Neural Scene Representations and Differentiable Rendering<br><span style="font-style: italic;">Delft University of Technology</span>, 2022 <br><a href="https://m-niemeyer.github.io/assets/pdf/diffrend-slides.pdf" target="_blank">Slides</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/games-talk.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Implicit Neural Scene Representations and 3D-Aware Generative Modelling<br><span style="font-style: italic;">GAMES Webinar Series</span>, 2022 <br><a href="https://m-niemeyer.github.io/assets/pdf/games-slides.pdf" target="_blank">Slides</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/adobe-pres.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Generative Neural Scene Representations<br><span style="font-style: italic;">Adobe Research</span>, 2021 <br><a href="https://m-niemeyer.github.io/assets/pdf/gnsr-slides.pdf" target="_blank">Slides</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/tum-lecture-img.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Implicit Scene Representations and Neural Rendering<br><span style="font-style: italic;">Technical University Munic - AI Lecture Series</span>, 2021 <br><a href="https://m-niemeyer.github.io/assets/pdf/isr_nr.pdf" target="_blank">Slides</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/amazon.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Generative Neural Scene Representations for 3D-Aware Image Synthesis<br><span style="font-style: italic;">AIT (ETH)</span>, 2021 <br><a href="https://m-niemeyer.github.io/assets/pdf/gnsr_slides.pdf" target="_blank">Slides</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/amazon.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Generative Neural Scene Representations for 3D-Aware Image Synthesis<br><span style="font-style: italic;">Amazon Research</span>, 2021 <br><a href="https://m-niemeyer.github.io/assets/pdf/gnsr_slides.pdf" target="_blank">Slides</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/mit.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Generative Neural Scene Representations for 3D-Aware Image Synthesis<br><span style="font-style: italic;">Massachusetts Institute of Technology</span>, 2021 <br><a href="https://yenchenlin.me/3D-representation-reading/assets/Michael.pdf" target="_blank">Slides</a> / <a href="https://www.youtube.com/watch?v=scnXyCSMJF4" target="_blank">Recording</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/fraunhofer.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">KI Forschung und 3D Deep Learning<br><span style="font-style: italic;">Frauenhofer IAO event 100 KI Talents</span>, 2020 <br><a href="https://tiny.cc/100-ki-talente" target="_blank">Slides</a> / <a href="https://www.youtube.com/watch?v=lpX85uNFZ0s" target="_blank">Recording</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/gtc.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">3D Deep Learning in Function Space<br><span style="font-style: italic;">NVIDIA. NVIDIA GPU Technology Conference (GTC)</span>, 2020 <br><a href="https://m-niemeyer.github.io/slides/gtc/" target="_blank">Slides</a> / <a href="https://www.youtube.com/watch?v=U_jIN3qWVEw" target="_blank">Recording</a> </div> </div> </div>
            </div>
        </div>
        <div class="row" style="margin-top: 3em; margin-bottom: 1em;">
            
            <div class="col-sm-12" style="">
                <h4>Homepage Template</h4>
                <p>
                    Feel free to use this website as a template! It is fully responsive and very easy to use and maintain as it uses a python script that crawls your bib files to automatically add the papers and talks. If you find it helpful, please add a link to my website - I will also add a link to yours (if you want). <a href="https://github.com/m-niemeyer/m-niemeyer.github.io" target="_blank">Checkout the github repository for instructions on how to use it</a>. <br>
                    <a href="https://kashyap7x.github.io/" target="_blank">&#9883;</a>
                    <a href="https://kait0.github.io/" target="_blank">&#9883;</a>
                </p>
            </div>
    
        </div>
    </div>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
      integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
      crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
      integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
      crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
      integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
      crossorigin="anonymous"></script>
</body>

</html>
    